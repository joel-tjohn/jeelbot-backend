import json
import csv
import random
import os
from flask import Flask, request, jsonify
from flask_cors import CORS
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
import google.generativeai as genai

# --------------------------------------------------
# ðŸ”‘ GEMINI SETUP
# --------------------------------------------------
# It pulls the key safely from the variable you added to Render
api_key = os.environ.get("AIzaSyB6LQlmgH11j6bz8PR9kDH-O633y6pisEQ")

if not api_key:
    print("âš ï¸ Error: Gemini_API_Key not found in environment!")
else:
    genai.configure(api_key=api_key)
    # Using the latest 1.5-flash model for fast, efficient responses
    gemini_model = genai.GenerativeModel("gemini-1.5-flash")

# --------------------------------------------------
# ðŸš€ FLASK APP
# --------------------------------------------------
app = Flask(__name__)
CORS(app)

# --------------------------------------------------
# ðŸ“š LOAD KNOWLEDGE BASE & DATASET
# --------------------------------------------------
with open("knowledge_base.json", "r", encoding="utf-8") as f:
    knowledge_base = json.load(f)

training_data = []
with open("dataset.csv", "r", encoding="utf-8") as f:
    reader = csv.reader(f)
    next(reader)
    for row in reader:
        if len(row) >= 2:
            training_data.append((row[0].lower().strip(), row[1].strip()))

X_train = [x[0] for x in training_data]
y_train = [x[1] for x in training_data]

# --------------------------------------------------
# ðŸ§  TRAIN INTENT MODEL
# --------------------------------------------------
model = make_pipeline(
    CountVectorizer(ngram_range=(1, 2)),
    LogisticRegression(max_iter=1000)
)
model.fit(X_train, y_train)

print(f"âœ… Loaded {len(training_data)} samples")
print("âœ… JeelBot ready")

# --------------------------------------------------
# ðŸ’¾ SESSION MEMORY & HELPERS
# --------------------------------------------------
sessions = {}

def normalize_text(text):
    return text.lower().strip()

def random_from_list(items, last=None):
    if not items: return ""
    if last and len(items) > 1:
        items = [i for i in items if i != last]
    return random.choice(items)

def is_greeting(text):
    greetings = ["hi", "hello", "hey", "namaste", "morning", "evening"]
    return any(g in text for g in greetings)

def is_small_talk(text):
    return text in ["ok", "okay", "hmm", "yes", "yeah", "cool", "fine"]

def is_yoga_domain(text):
    yoga_keywords = [
        "yoga", "asana", "pose", "pranayama", "meditation", "breath", 
        "stress", "relax", "sleep", "flexibility", "sun salutation","wellness"
    ]
    return any(word in text for word in yoga_keywords)

# --------------------------------------------------
# ðŸ¤– GEMINI ENHANCER (STRICT YOGA ONLY)
# --------------------------------------------------
def gemini_reply(prompt_text, context_data=""):
    try:
        # System prompt ensures the bot stays strictly within the yoga domain
        prompt = f"""
You are JeelBot, an intelligent yoga and wellness assistant.
CONTEXT INFORMATION: {context_data}

Rules:
- Only talk about yoga, meditation, breathing, sleep, or wellness.
- If the user asks something outside these topics, politely refuse.
- Use the CONTEXT INFORMATION to provide accurate details.
- Keep responses short (1â€“2 sentences) and supportive.
- Do not mention you are an AI.

User message: {prompt_text}
"""
        response = gemini_model.generate_content(prompt)
        return response.text.strip() if response.text else ""
    except Exception as e:
        print(f"âŒ Gemini Error: {e}")
        return ""

# --------------------------------------------------
# ðŸ’¬ CHAT ROUTE
# --------------------------------------------------
@app.route("/chat", methods=["POST"])
def chat():
    data = request.json or {}
    raw_message = data.get("message", "")
    session_id = data.get("session_id", "default")

    message = normalize_text(raw_message)

    if session_id not in sessions:
        sessions[session_id] = {"last_intent": None, "last_reply": None}

    context = sessions[session_id]

    # 1. GREETING
    if is_greeting(message):
        base = random_from_list(knowledge_base["greeting"]["responses"], context.get("last_reply"))
        follow = gemini_reply("Add a friendly yoga-related follow-up question")
        reply = f"{base}\n{follow}" if follow else base
        context["last_reply"] = base
        return jsonify({"response": reply})

    # 2. STRICT DOMAIN FILTER
    if not is_yoga_domain(message) and not message.isdigit():
        return jsonify({"response": "Iâ€™m JeelBot ðŸŒ¿ I only answer yoga and wellness questions."})

    # 3. SMALL TALK
    if is_small_talk(message):
        follow = gemini_reply("Respond casually within yoga context", "Keep it very brief.")
        return jsonify({"response": follow or "Alright ðŸŒ¿"})

    # 4. FOLLOW-UP OPTIONS (Numeric menu)
    if context.get("last_intent") and message in ["1", "2", "3", "4", "5"]:
        intent = context["last_intent"]
        info = knowledge_base.get(intent, {})
        if message == "1":
            return jsonify({"response": f"â° Duration: {info.get('duration')}\nðŸ•’ Best time: {info.get('best_time')}"})
        if message == "2":
            return jsonify({"response": "ðŸŒ¬ï¸ Breathing:\nâ€¢ " + "\nâ€¢ ".join(info.get("breathing", []))})
        if message == "3":
            poses = ", ".join(info.get("poses", []))
            ai_desc = gemini_reply(f"Briefly describe benefits of: {poses}")
            return jsonify({"response": f"ðŸ§˜ Poses:\nâ€¢ " + "\nâ€¢ ".join(info.get("poses", [])) + f"\n\n{ai_desc}"})
        if message == "4":
            return jsonify({"response": "âš ï¸ Safety Tips:\nâ€¢ " + "\nâ€¢ ".join(info.get("tips", []))})
        if message == "5":
            context["last_intent"] = None
            return jsonify({"response": "Sure ðŸŒ¿ What would you like to explore next?"})

# --------------------------------------------------
    # ðŸ§  5. INTENT PREDICTION & SMART FALLBACK
    # --------------------------------------------------
    probs = model.predict_proba([message])[0]
    confidence = max(probs)
    intent = model.classes_[probs.argmax()]

    # A: HIGH CONFIDENCE -> Use your Knowledge Base JSON
    if confidence > 0.4 and intent != "fallback":
        if intent in knowledge_base:
            context["last_intent"] = intent
            intro = gemini_reply(message, str(knowledge_base[intent]))
            
            return jsonify({
                "response": f"{intro}\n\n"
                            "What would you like to explore?\n"
                            "1ï¸âƒ£ Duration & Time\n"
                            "2ï¸âƒ£ Breathing\n"
                            "3ï¸âƒ£ Poses\n"
                            "4ï¸âƒ£ Safety Tips\n"
                            "5ï¸âƒ£ Another topic"
            })

    # B: LOW CONFIDENCE OR FALLBACK -> SMART GEMINI FILTER
    # This prevents the "I only answer yoga questions" error for general wellness.
    smart_prompt = (
        f"The user said '{raw_message}'. If this is even slightly related to "
        "health, wellness, or yoga, give a friendly 1-sentence tip. If it is "
        "totally random (like coding or movies), politely decline."
    )
    
    # We pass the smart instruction as the 'context' to your existing function
    ai_response = gemini_reply(raw_message, smart_prompt)
    
    return jsonify({"response": ai_response or "I'm here for your yoga and wellness needs! ðŸŒ¿"})
    # 6. FALLBACK
    return jsonify({"response": "I'm not sure about that. Try asking about a specific yoga pose or wellness topic ðŸŒ¿"})

if __name__ == "__main__":
    # Get port from environment for Render deployment
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)